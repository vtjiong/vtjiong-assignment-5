{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qlkjkwln_B4w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uLOaRQmx_B4w"
   },
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train=None\n",
    "        self.y_train=None\n",
    "        self.weighted = True\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # TODO: Implement the fit method\n",
    "        self.X_train=X\n",
    "        self.y_train=y\n",
    "\n",
    "    def predict(self, X):\n",
    "     # Convert X to numpy array\n",
    "        probabilities = []\n",
    "        # Compute distances between each point in X and all points in X_train\n",
    "        distances = self.compute_distance(X, self.X_train)\n",
    "\n",
    "        # Iterate over each sample's distances\n",
    "        for dist in distances:\n",
    "            k_indices = np.argsort(dist)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices].astype(int)\n",
    "\n",
    "            # Compute the probability of class 1\n",
    "            prob_class_1 = np.sum(k_nearest_labels == 1) / self.k\n",
    "            probabilities.append(prob_class_1)\n",
    "        return np.array(probabilities)\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        # TODO: Implement distance computation based on self.distance_metric\n",
    "        # Hint: Use numpy operations for efficient computation\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1[:, np.newaxis] - X2) ** 2, axis=2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1[:, np.newaxis] - X2), axis=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Distance metric {self.distance_metric} not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6KRKnisM_B4w"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_path, test_path=None):\n",
    "    # Load the train data\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path) if test_path else None\n",
    "\n",
    "    # Concatenate train and test data if test data is provided\n",
    "    if test_data is not None:\n",
    "        combined_data = pd.concat([train_data, test_data], keys=['train', 'test'])\n",
    "    else:\n",
    "        combined_data = train_data\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    combined_data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "    # Handle missing values for numerical columns (replace with median)\n",
    "    num_cols = combined_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in num_cols:\n",
    "        median_val = combined_data[col].median()\n",
    "        combined_data[col].fillna(median_val, inplace=True)\n",
    "\n",
    "    # Handle missing values for categorical columns (replace with mode)\n",
    "    cat_cols = combined_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        mode_val = combined_data[col].mode()[0]\n",
    "        combined_data[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "    # One-hot encoding for 'Geography' (pandas get_dummies)\n",
    "    combined_data = pd.get_dummies(combined_data, columns=['Geography'], drop_first=True)\n",
    "\n",
    "    # Manual encoding for 'Gender' (replace 'Male' with 1 and 'Female' with 0)\n",
    "    combined_data['Gender'] = combined_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
    "\n",
    "    # If test data is provided, split combined data back into train and test\n",
    "    \n",
    "    train_data = combined_data.xs('train')\n",
    "    test_data = combined_data.xs('test')\n",
    "\n",
    "        # Ensure 'Exited' column is dropped from test data (if present)\n",
    "    if 'Exited' in test_data.columns:\n",
    "        test_data.drop('Exited', axis=1, inplace=True)\n",
    "\n",
    "        # Align test set with training set columns\n",
    "    test_data = test_data.reindex(columns=train_data.drop('Exited', axis=1).columns, fill_value=0)\n",
    "\n",
    "    # Separate features (X) and target (y) for training set\n",
    "    X_train = train_data.drop('Exited', axis=1)\n",
    "    y_train = train_data['Exited']\n",
    "\n",
    "    # Feature scaling using manual robust scaling (subtract median and divide by IQR)\n",
    "    X_train_scaled = X_train.copy()\n",
    "    scaling_params = {}  # Dictionary to store the median and IQR for each column\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        if X_train[col].dtype in [np.float64, np.int64]:  # Only scale numeric columns\n",
    "            median_val = X_train[col].median()\n",
    "            iqr_val = X_train[col].quantile(0.75) - X_train[col].quantile(0.25)\n",
    "            \n",
    "            # If IQR is 0 (constant feature), avoid division by 0 by scaling with 1\n",
    "            if iqr_val == 0:\n",
    "                iqr_val = 1\n",
    "            \n",
    "            # Store the scaling parameters\n",
    "            scaling_params[col] = {'median': median_val, 'iqr': iqr_val}\n",
    "            \n",
    "            # Scale the training data\n",
    "            X_train_scaled[col] = (X_train[col] - median_val) / iqr_val\n",
    "\n",
    "    if test_data is not None:\n",
    "        X_test_scaled = test_data.copy()\n",
    "        for col in test_data.columns:\n",
    "            if test_data[col].dtype in [np.float64, np.int64]:  # Only scale numeric columns\n",
    "                # Use the median and IQR from the training set\n",
    "                median_val = scaling_params[col]['median']\n",
    "                iqr_val = scaling_params[col]['iqr']\n",
    "                \n",
    "                # Scale the test data using the training set's statistics\n",
    "                X_test_scaled[col] = (test_data[col] - median_val) / iqr_val\n",
    "        # Convert to numpy arrays and ensure proper 2D shape\n",
    "        return np.array(X_train_scaled,dtype=np.float64), np.array(y_train,dtype=np.float64), np.array(X_test_scaled,dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oJ2qY2JJ_B4x"
   },
   "outputs": [],
   "source": [
    "def kfold(X, y, n_splits=5):\n",
    "    # Shuffle the indices of X and y\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split the indices into roughly equal parts\n",
    "    fold_sizes = np.full(n_splits, len(X) // n_splits, dtype=int)\n",
    "    fold_sizes[:len(X) % n_splits] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        folds.append(indices[start:stop])\n",
    "        current = stop\n",
    "\n",
    "    return folds\n",
    "\n",
    "def roc_auc(y_true, y_pred):\n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Sort instances by the predicted score (y_pred)\n",
    "    sorted_indices = np.argsort(y_pred)[::-1]\n",
    "    y_true_sorted = y_true[sorted_indices]\n",
    "\n",
    "    # Count the total number of positives and negatives\n",
    "    pos_count = np.sum(y_true == 1)\n",
    "    neg_count = np.sum(y_true == 0)\n",
    "\n",
    "    # Calculate the true positive rate (TPR) and false positive rate (FPR)\n",
    "    tpr = np.cumsum(y_true_sorted == 1) / pos_count\n",
    "    fpr = np.cumsum(y_true_sorted == 0) / neg_count\n",
    "\n",
    "    # Use the trapezoidal rule to calculate AUC\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    return auc\n",
    "\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    \n",
    "    # Initialize list to store AUC scores for each fold\n",
    "    auc_scores = []\n",
    "\n",
    "    # Perform manual KFold cross-validation\n",
    "    folds = kfold(X, y, n_splits)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for fold in folds:\n",
    "        # Split data into training and testing sets using index values\n",
    "        test_index = fold\n",
    "        train_index = np.setdiff1d(np.arange(len(X)), test_index)\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fit the KNN model on the training data\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        # Calculate ROC AUC score based on binary classification\n",
    "        auc = roc_auc(y_test, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Return the list of AUC scores and the average AUC\n",
    "    return auc_scores, np.mean(auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mbwi6Wbp_B4x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/3s3bcbys3qs05zfg3_jzxfhc0000gn/T/ipykernel_3878/3810826123.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data[col].fillna(median_val, inplace=True)\n",
      "/var/folders/td/3s3bcbys3qs05zfg3_jzxfhc0000gn/T/ipykernel_3878/3810826123.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data[col].fillna(mode_val, inplace=True)\n",
      "/var/folders/td/3s3bcbys3qs05zfg3_jzxfhc0000gn/T/ipykernel_3878/3810826123.py:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_data['Gender'] = combined_data['Gender'].replace({'Male': 1, 'Female': 0})\n",
      "/var/folders/td/3s3bcbys3qs05zfg3_jzxfhc0000gn/T/ipykernel_3878/3810826123.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.drop('Exited', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: ([0.8575250265840324, 0.8824342640281919, 0.8674058425872627, 0.8601504131938914, 0.885742608249612], 0.8706516309285981)\n",
      "Testing k=3, metric=euclidean, ROC=0.8443476329909609\n",
      "Testing k=3, metric=manhattan, ROC=0.8401710968641847\n",
      "Testing k=5, metric=euclidean, ROC=0.8706516309285981\n",
      "Testing k=5, metric=manhattan, ROC=0.8677401821172422\n",
      "Testing k=7, metric=euclidean, ROC=0.8845887436483502\n",
      "Testing k=7, metric=manhattan, ROC=0.884359103919903\n",
      "Testing k=9, metric=euclidean, ROC=0.891650819581761\n",
      "Testing k=9, metric=manhattan, ROC=0.8898152650500535\n",
      "Testing k=11, metric=euclidean, ROC=0.8971864256096829\n",
      "Testing k=11, metric=manhattan, ROC=0.8957542164668038\n",
      "Testing k=13, metric=euclidean, ROC=0.8996697530593858\n",
      "Testing k=13, metric=manhattan, ROC=0.8983279137367746\n",
      "Testing k=15, metric=euclidean, ROC=0.900885058925762\n",
      "Testing k=15, metric=manhattan, ROC=0.9002097004876738\n",
      "Testing k=17, metric=euclidean, ROC=0.9033155011550138\n",
      "Testing k=17, metric=manhattan, ROC=0.903057471318359\n",
      "Testing k=19, metric=euclidean, ROC=0.9054435356802054\n",
      "Testing k=19, metric=manhattan, ROC=0.9053260255742931\n",
      "Testing k=21, metric=euclidean, ROC=0.9065952097299869\n",
      "Testing k=21, metric=manhattan, ROC=0.9063641620303506\n",
      "Testing k=23, metric=euclidean, ROC=0.9078603250193232\n",
      "Testing k=23, metric=manhattan, ROC=0.9068639089099785\n",
      "Testing k=25, metric=euclidean, ROC=0.9081991037036768\n",
      "Testing k=25, metric=manhattan, ROC=0.9075842235552795\n",
      "Testing k=27, metric=euclidean, ROC=0.9086554926306141\n",
      "Testing k=27, metric=manhattan, ROC=0.90882735546035\n",
      "Testing k=31, metric=euclidean, ROC=0.9088702538606613\n",
      "Testing k=31, metric=manhattan, ROC=0.9099127102535413\n",
      "Testing k=33, metric=euclidean, ROC=0.9091175157798966\n",
      "Testing k=33, metric=manhattan, ROC=0.9105990039479618\n",
      "Testing k=35, metric=euclidean, ROC=0.9095492874239127\n",
      "Testing k=35, metric=manhattan, ROC=0.9104731023458813\n",
      "Testing k=37, metric=euclidean, ROC=0.9095494124622496\n",
      "Testing k=37, metric=manhattan, ROC=0.911423064848145\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('./train.csv', './test.csv')\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "# Hyperparameter tuning\n",
    "\n",
    "def hyperparameter_tuning(X, y):\n",
    "    # Define the grid of hyperparameters\n",
    "    param_grid = {\n",
    "        'k': [3, 5, 7, 9, 11,13,15,17,19,21,23,25,27,31,33,35,37],  # Test different values of k\n",
    "        'distance_metric': ['euclidean', 'manhattan']  # Test different distance metrics\n",
    "    }\n",
    "\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "\n",
    "    # Grid search over the hyperparameters\n",
    "    for k in param_grid['k']:\n",
    "        for metric in param_grid['distance_metric']:\n",
    "            knn = KNN(k=k, distance_metric=metric)\n",
    "            scores, avg_auc = cross_validate(X, y, knn)\n",
    "            print(f\"Testing k={k}, metric={metric}, ROC={avg_auc}\")\n",
    "\n",
    "            # Keep track of the best hyperparameters\n",
    "            if avg_auc > best_score:\n",
    "                best_score = avg_auc\n",
    "                best_params = {'k': k, 'distance_metric': metric}\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# Get the best hyperparameters using cross-validation\n",
    "best_params = hyperparameter_tuning(X, y)\n",
    "\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "knn = KNN(k=best_params['k'], distance_metric=best_params['distance_metric'])\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = knn.predict(X_test)\n",
    "# Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('./test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
